{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW5 - Brian Hicks, Joe Everton\n",
    "## CS 498, Applied Machine Learning\n",
    "Using the ADL dataset, available [here](https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.metrics.pairwise import paired_euclidean_distances, euclidean_distances\n",
    "# import scipy.spatial.distance\n",
    "# from scipy.linalg import eigh as largest_eigh\n",
    "# import sklearn.metrics\n",
    "# from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ntpath\n",
    "# https://stackoverflow.com/questions/8384737/extract-file-name-from-path-no-matter-what-the-os-path-format\n",
    "def path_leaf(path):\n",
    "    head, tail = ntpath.split(path)\n",
    "    return tail or ntpath.basename(head)\n",
    "\n",
    "def load_data():\n",
    "  dataset = []\n",
    "  labels = []\n",
    "  label_index = 0\n",
    "  for dirname, dirnames, filenames in os.walk('HMP_Dataset'):\n",
    "      # target all leaf directories not ending with '_MODEL'.\n",
    "      if len(dirnames) == 0 and '_MODEL' not in dirname:\n",
    "        class_name = path_leaf(dirname)\n",
    "        labels.append(class_name)\n",
    "#         print(\"dirname: {}, filenames: {}\".format(dirname, len(filenames)))\n",
    "        for filename in filenames:\n",
    "#             print(os.path.join(dirname, filename))\n",
    "            dataset.append((np.loadtxt(os.path.join(dirname, filename)), label_index))\n",
    "        label_index += 1\n",
    "  return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_flatten_example(example, k, offset):\n",
    "  chunk_list = np.array_split(example, np.arange(k, len(data), step=k))\n",
    "  if len(chunk_list[-1]) != k:\n",
    "    chunk_list = chunk_list[:-1]\n",
    "  if offset != k:\n",
    "    chunk_list = chunk_list[1:]\n",
    "  chunk_list = [np.ravel(chunk) for chunk in chunk_list]\n",
    "  return chunk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class h_kmeans:\n",
    "  n_jobs = -1\n",
    "  def __init__(self, k_breadth):\n",
    "    # k_breadth is a vector of K for each depth.  The depth of the tree == length of k_breadth.\n",
    "    self.my_k = k_breadth\n",
    "    # print (\"Initializing KMeans, n_clusters = {}\".format(self.my_k[0]))\n",
    "    self.km = KMeans(n_clusters=self.my_k[0], n_jobs=h_kmeans.n_jobs)\n",
    "    self.children = []\n",
    "    if len(k_breadth) > 1:\n",
    "      # Remove my k, pass the rest to the children.\n",
    "      self.children = [h_kmeans(k_breadth[1:]) for km in range(self.my_k[0])]\n",
    "      # self.children = [h_kmeans(k_breadth[1:])] * self.my_k[0]\n",
    "\n",
    "  def fit(self, X):\n",
    "    self.km.fit(X)\n",
    "    if len(self.children) > 0:\n",
    "      clusters = self.km.predict(X)\n",
    "      for index, child_node in enumerate(self.children):\n",
    "        # pick out the rows that were predicted for cluster child_node.\n",
    "        match = clusters == index\n",
    "        print(\"fitting child using {} rows.\".format(np.sum(match)))\n",
    "        child_node.fit(X[match])\n",
    "  \n",
    "  def predict(self, X):\n",
    "    if len(self.children) == 0:\n",
    "      clusters = self.km.predict(X)\n",
    "      return clusters\n",
    "    if len(self.children) > 0:\n",
    "      clusters = self.km.predict(X)\n",
    "      depth_clusters = []\n",
    "      # TODO: We could pass sample_weight, and have it be 0 where it doesn't \n",
    "      # belong to this child, and 1 where it does.  That would get rid of the\n",
    "      # for loop.\n",
    "      for i in range(len(X)):\n",
    "        # a cluster anywhere on the tree should have a unique id for histogramming\n",
    "        # This math is supposed to use children results to get the flattened cluster\n",
    "        # index.\n",
    "        depth_clusters.append(\n",
    "          clusters[i] * self.myk[1] + self.children[clusters[i]].predict(X[i]))\n",
    "      return depth_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut into k-sized chunks and fill the dictionary.\n",
    "k = 32\n",
    "# TODO: dictionary is a poor name for this.\n",
    "dictionary = []\n",
    "for example in dataset:\n",
    "  data = example[0]\n",
    "  for offset in range(0, k, 11): # 0, 11, 22, to get about 3 x 13544 chunks.\n",
    "    split_data = split_and_flatten_example(data, k, k - offset)\n",
    "    # print(\"example size: {} split into {} chunks\".format(data.shape,len(split_data)))\n",
    "    dictionary.extend(split_data)\n",
    "dictionary = np.array(dictionary) # convert from list of arrays to 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run k-means\n",
    "# km = KMeans(n_clusters=480, random_state=0, n_jobs=2).fit(dictionary)\n",
    "km = h_kmeans((40,12))\n",
    "km.fit(dictionary)\n",
    "# km.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=480, random_state=0, n_jobs=2).fit(dictionary)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "subdict = dictionary[:20]\n",
    "clusters = km.predict(subdict)\n",
    "for i, cluster in enumerate(clusters[clusters >= 400]):\n",
    "  print(\"i {} cluster {}\".format(i, cluster))\n",
    "  cluster = -1\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split experiments.\n",
    "Probably going to use kfold anyway."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(dataset[0][0].shape)\n",
    "train, test = train_test_split(dataset, test_size=0.33)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = np.ones((2167,3))\n",
    "my_split = np.array_split(data, np.arange(32,len(data),step=32))\n",
    "len(my_split[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with NDArray Views.\n",
    "Never did find a way to use integer indexing to produce a view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_to_value(a, value):\n",
    "  a.fill(value)\n",
    "\n",
    "foo = np.tile(np.array(np.arange(5)), 5)\n",
    "set_all_to_value(foo.view()[[1, 2, 8, 11]], -1)\n",
    "foo[[1, 2, 8, 11]][2] = -1\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.array([(1, 2),(3,4)], dtype=[('aasdf', np.int8), ('bwerewr', np.int8)])\n",
    "x = np.array([1, 2, 3, 4])# , dtype=[('aasdf', np.int8), ('bwerewr', np.int8)])\n",
    "print(x)\n",
    "#xv = x.view(dtype=np.int8).reshape(-1,2)\n",
    "xv = x.view()\n",
    "print(xv)\n",
    "y = xv[[1, 2],]\n",
    "y[1] = -20\n",
    "print(y)\n",
    "print(xv)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(5)\n",
    "x\n",
    "\n",
    "y = x[::2]\n",
    "y\n",
    "\n",
    "y[0] = 3\n",
    "x\n",
    "\n",
    "np.sum(x == 3)\n",
    "# x == 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
